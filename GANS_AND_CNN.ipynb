{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "549c16bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c8b196",
   "metadata": {},
   "source": [
    "### GANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b7db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'Datasets\\\\Covid_Gans_Images'\n",
    "print(os.listdir(DATA_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0da3f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(DATA_DIR+'/images')[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c952776",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "batch_size = 1\n",
    "stats = (0.5), (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3ca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ImageFolder(DATA_DIR, \n",
    "        transform = T.Compose([\n",
    "            T.Resize(image_size),\n",
    "#             T.CenterCrop(image_size),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(*stats)\n",
    "        ])\n",
    ")\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbfd65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(img_tensors):\n",
    "    return img_tensors * stats[1] + stats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229960a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, nmax=10):\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8).permute(1,2,0))\n",
    "    \n",
    "def show_batch(dl, nmax=64):\n",
    "    for images, _ in dl:\n",
    "        show_images(images, nmax)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f02f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9089f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if availabel, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosem device\"\"\"\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df8605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5deec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35cab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db68d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = nn.Sequential(\n",
    "    \n",
    "    # in: 3*64*64\n",
    "    nn.Conv2d(3,64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # out: 64*32*32\n",
    "    \n",
    "    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # out: 128 * 16* 16\n",
    "    \n",
    "    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # out: 256 * 8* 8\n",
    "    \n",
    "    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(512),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # out: 512 * 4*4\n",
    "    \n",
    "    nn.Conv2d(512,1 , kernel_size=4, stride=1, padding=0, bias=False),\n",
    "    # out: 1*1*1\n",
    "    \n",
    "    nn.Flatten(),\n",
    "    nn.Sigmoid()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a167de",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = to_device(discriminator, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9207044",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d723c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = nn.Sequential(\n",
    "    # in: latent_size x 1 x 1\n",
    "\n",
    "    nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "    nn.BatchNorm2d(512),\n",
    "    nn.ReLU(True),\n",
    "    # out: 512 x 4 x 4\n",
    "\n",
    "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(True),\n",
    "    # out: 256 x 8 x 8\n",
    "\n",
    "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(True),\n",
    "    # out: 128 x 16 x 16\n",
    "\n",
    "    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(True),\n",
    "    # out: 64 x 32 x 32\n",
    "\n",
    "    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.Tanh()\n",
    "    # out: 3 x 64 x 64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05516630",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb = torch.randn(batch_size, latent_size, 1, 1) # random latent tensors\n",
    "fake_images = generator(xb)\n",
    "print(fake_images.shape)\n",
    "show_images(fake_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429565a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = to_device(generator, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b488426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(real_images, opt_d):\n",
    "    # Clear discriminator gradients\n",
    "    opt_d.zero_grad()\n",
    "    \n",
    "    # Pass real images through discriminator\n",
    "    real_preds = discriminator(real_images)\n",
    "    real_targets = torch.ones(real_images.size(0), 1, device=device)\n",
    "    real_loss = F.binary_cross_entropy(real_preds, real_targets)\n",
    "    real_score = torch.mean(real_preds).item()\n",
    "    \n",
    "    # Generate fake images\n",
    "    latent = torch.randn(batch_size, latent_size, 1,1, device=device)\n",
    "    fake_images = generator(latent)\n",
    "    \n",
    "    # Pass fake images through discriminator\n",
    "    fake_targets = torch.zeros(fake_images.size(0), 1, device=device)\n",
    "    fake_preds = discriminator(fake_images)\n",
    "    fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n",
    "    fake_score = torch.mean(fake_preds).item()\n",
    "    \n",
    "    # Update discriminator weights\n",
    "    loss = real_loss + fake_loss\n",
    "    loss.backward()\n",
    "    opt_d.step()\n",
    "    \n",
    "    return loss.item(), real_score, fake_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b3801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(opt_g):\n",
    "    # Clear generator gradients\n",
    "    opt_g.zero_grad()\n",
    "    \n",
    "    # Generate fake images\n",
    "    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
    "    fake_images = generator(latent)\n",
    "    \n",
    "    # Try to fool the discriminator\n",
    "    preds = discriminator(fake_images)\n",
    "    targets = torch.ones(batch_size, 1, device=device)\n",
    "    loss = F.binary_cross_entropy(preds, targets)\n",
    "    \n",
    "    # Update generator weights\n",
    "    loss.backward()\n",
    "    opt_g.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa8f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir = 'generated_covid'\n",
    "os.makedirs(sample_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac84597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_samples(index, latent_tensors, show=True):\n",
    "    fake_images = generator(latent_tensors)\n",
    "    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n",
    "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n",
    "    print('Saving', fake_fname)\n",
    "    \n",
    "    if show:\n",
    "        fig, ax = plt.subplots(figsize=(8,8))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd92b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_latent = torch.randn(1, latent_size, 1, 1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea1c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_samples(0, fixed_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30caa1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, start_idx=1):\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Losses & scores\n",
    "    losses_g = []\n",
    "    losses_d = []\n",
    "    real_scores = []\n",
    "    fake_scores = []\n",
    "    \n",
    "    # Create optimizers\n",
    "    opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for real_images, _ in tqdm(train_dl):\n",
    "            # Train discriminator\n",
    "            loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n",
    "            # Train generator\n",
    "            loss_g = train_generator(opt_g)\n",
    "            \n",
    "        # Record losses & scores\n",
    "        losses_g.append(loss_g)\n",
    "        losses_d.append(loss_d)\n",
    "        real_scores.append(real_score)\n",
    "        fake_scores.append(fake_score)\n",
    "        \n",
    "        # Log losses & scores (last batch)\n",
    "        print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n",
    "            epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n",
    "    \n",
    "        # Save generated images\n",
    "        save_samples(epoch+start_idx, fixed_latent, show=False)\n",
    "    \n",
    "    return losses_g, losses_d, real_scores, fake_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3761a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0002\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13a28b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fit(epochs, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814a6d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_g, losses_d, real_scores, fake_scores = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa9b428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model checkpoints\n",
    "torch.save(generator.state_dict(), 'G.pth')\n",
    "torch.save(discriminator.state_dict(), 'D.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00575726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189d37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('generated_covid\\\\generated-images-0001.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e63873",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('generated_covid\\\\generated-images-0048.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730b00cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses_d, '-')\n",
    "plt.plot(losses_g, '-')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Discriminator','Generator'])\n",
    "plt.title('Losses');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be07a166",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(real_scores, '-')\n",
    "plt.plot(fake_scores, '-')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('score')\n",
    "plt.legend(['Real', 'Fake'])\n",
    "plt.title('Scores');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd594f0d",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6cfa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_TRAIN = \"Datasets\\\\Covid_Normal_Images\\\\train\\\\\"\n",
    "DIR_TEST = \"Datasets\\\\Covid_Normal_Images\\\\test\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38dfb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = os.listdir(DIR_TRAIN) \n",
    "test_imgs = os.listdir(DIR_TEST)\n",
    "\n",
    "print(imgs[:5])\n",
    "print(test_imgs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91fedc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_list = [img for img in imgs if img.split(\"-\")[0] == \"COVID\"]\n",
    "normal_list = [img for img in imgs if img.split(\"-\")[0] == \"Normal\"]\n",
    "\n",
    "print(\"No of Covid Images: \",len(covid_list))\n",
    "print(\"No of Normal Images: \",len(normal_list))\n",
    "\n",
    "class_to_int = {\"COVID\" : 0, \"Normal\" : 1}\n",
    "int_to_class = {0 : \"COVID\", 1 : \"Normal\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca34b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform():\n",
    "    return T.Compose([\n",
    "        T.Resize(64),\n",
    "#         T.CenterCrop(64),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.5),(0.5))\n",
    "    ])\n",
    "    \n",
    "def get_val_transform():\n",
    "    return T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.5),(0.5))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d78ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Covid_Normal_Image(Dataset):\n",
    "    \n",
    "    def __init__(self, imgs, class_to_int, mode = \"train\", transforms = None):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.imgs = imgs\n",
    "        self.class_to_int = class_to_int\n",
    "        self.mode = mode\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image_name = self.imgs[idx]\n",
    "        \n",
    "        ### Reading, converting and normalizing image\n",
    "        #img = cv2.imread(DIR_TRAIN + image_name, cv2.IMREAD_COLOR)\n",
    "        #img = cv2.resize(img, (224,224))\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        #img /= 255.\n",
    "        img = Image.open(DIR_TRAIN + image_name)\n",
    "        img = img.resize((64, 64))\n",
    "        \n",
    "        if self.mode == \"train\" or self.mode == \"val\":\n",
    "        \n",
    "            ### Preparing class label\n",
    "            label = self.class_to_int[image_name.split(\"-\")[0]]\n",
    "            label = torch.tensor(label, dtype = torch.float32)\n",
    "\n",
    "            ### Apply Transforms on image\n",
    "            img = self.transforms(img)\n",
    "\n",
    "            return img, label\n",
    "        \n",
    "        elif self.mode == \"test\":\n",
    "            \n",
    "            ### Apply Transforms on image\n",
    "            img = self.transforms(img)\n",
    "\n",
    "            return img\n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c9abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Covid_Normal_Image(train_imgs, class_to_int, mode = \"train\", transforms = get_train_transform())\n",
    "val_dataset = Covid_Normal_Image(val_imgs, class_to_int, mode = \"val\", transforms = get_val_transform())\n",
    "test_dataset = Covid_Normal_Image(test_imgs, class_to_int, mode = \"test\", transforms = get_val_transform())\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "#     num_workers = 12,\n",
    "    batch_size = 1,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_data_loader = DataLoader(\n",
    "    dataset = val_dataset,\n",
    "#     num_workers = 12,\n",
    "    batch_size = 1,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    dataset = test_dataset,\n",
    "#     num_workers = 12,\n",
    "    batch_size = 1,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d31ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_data_loader:\n",
    "    fig, ax = plt.subplots(figsize = (10, 10))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.imshow(make_grid(images, 4).permute(1,2,0))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2055f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, trues):\n",
    "    \n",
    "    ### Converting preds to 0 or 1\n",
    "    preds = [1 if preds[i] >= 0.5 else 0 for i in range(len(preds))]\n",
    "    \n",
    "    ### Calculating accuracy by comparing predictions with true labels\n",
    "    acc = [1 if preds[i] == trues[i] else 0 for i in range(len(preds))]\n",
    "    \n",
    "    ### Summing over all correct predictions\n",
    "    acc = np.sum(acc) / len(preds)\n",
    "    \n",
    "    return (acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_data_loader):\n",
    "    \n",
    "    ### Local Parameters\n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ###Iterating over data loader\n",
    "    for images, labels in train_data_loader:\n",
    "        \n",
    "        #Loading images and labels to device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.reshape((labels.shape[0], 1)) # [N, 1] - to match with preds shape\n",
    "        \n",
    "        #Reseting Gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Forward\n",
    "        preds = model(images)\n",
    "        \n",
    "        #Calculating Loss\n",
    "        _loss = criterion(preds, labels)\n",
    "        loss = _loss.item()\n",
    "        epoch_loss.append(loss)\n",
    "        \n",
    "        #Calculating Accuracy\n",
    "        acc = accuracy(preds, labels)\n",
    "        epoch_acc.append(acc)\n",
    "        \n",
    "        #Backward\n",
    "        _loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    ###Overall Epoch Results\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    ###Acc and Loss\n",
    "    epoch_loss = np.mean(epoch_loss)\n",
    "    epoch_acc = np.mean(epoch_acc)\n",
    "    \n",
    "    ###Storing results to logs\n",
    "    train_logs[\"loss\"].append(epoch_loss)\n",
    "    train_logs[\"accuracy\"].append(epoch_acc)\n",
    "    train_logs[\"time\"].append(total_time)\n",
    "        \n",
    "    return epoch_loss, epoch_acc, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b1cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_one_epoch(val_data_loader, best_val_acc):\n",
    "    \n",
    "    ### Local Parameters\n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ###Iterating over data loader\n",
    "    for images, labels in val_data_loader:\n",
    "        \n",
    "        #Loading images and labels to device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.reshape((labels.shape[0], 1)) # [N, 1] - to match with preds shape\n",
    "        \n",
    "        #Forward\n",
    "        preds = model(images)\n",
    "        \n",
    "        #Calculating Loss\n",
    "        _loss = criterion(preds, labels)\n",
    "        loss = _loss.item()\n",
    "        epoch_loss.append(loss)\n",
    "        \n",
    "        #Calculating Accuracy\n",
    "        acc = accuracy(preds, labels)\n",
    "        epoch_acc.append(acc)\n",
    "    \n",
    "    ###Overall Epoch Results\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    ###Acc and Loss\n",
    "    epoch_loss = np.mean(epoch_loss)\n",
    "    epoch_acc = np.mean(epoch_acc)\n",
    "    \n",
    "    ###Storing results to logs\n",
    "    val_logs[\"loss\"].append(epoch_loss)\n",
    "    val_logs[\"accuracy\"].append(epoch_acc)\n",
    "    val_logs[\"time\"].append(total_time)\n",
    "    \n",
    "    ###Saving best model\n",
    "    if epoch_acc > best_val_acc:\n",
    "        best_val_acc = epoch_acc\n",
    "        torch.save(model.state_dict(),\"resnet50_best.pth\")\n",
    "        \n",
    "    return epoch_loss, epoch_acc, total_time, best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3303622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Covid_Normal_CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Covid_Normal_CNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=8192, out_features=600)\n",
    "        self.drop = nn.Dropout2d(0.25)\n",
    "        self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
    "        self.fc3 = nn.Linear(in_features=120, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7807e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Covid_Normal_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd58d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "# # Learning Rate Scheduler\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n",
    "\n",
    "#Loss Function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Logs - Helpful for plotting after training finishes\n",
    "train_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
    "val_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
    "\n",
    "# Loading model to device\n",
    "model.to(device)\n",
    "\n",
    "# No of epochs \n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5edece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_acc = 0\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    ###Training\n",
    "    loss, acc, _time = train_one_epoch(train_data_loader)\n",
    "    \n",
    "    #Print Epoch Details\n",
    "    print(\"\\nTraining\")\n",
    "    print(\"Epoch {}\".format(epoch+1))\n",
    "    print(\"Loss : {}\".format(round(loss, 4)))\n",
    "    print(\"Acc : {}\".format(round(acc, 4)))\n",
    "    print(\"Time : {}\".format(round(_time, 4)))\n",
    "    \n",
    "    ###Validation\n",
    "    loss, acc, _time, best_val_acc = val_one_epoch(val_data_loader, best_val_acc)\n",
    "    \n",
    "    #Print Epoch Details\n",
    "    print(\"\\nValidating\")\n",
    "    print(\"Epoch {}\".format(epoch+1))\n",
    "    print(\"Loss : {}\".format(round(loss, 4)))\n",
    "    print(\"Acc : {}\".format(round(acc, 4)))\n",
    "    print(\"Time : {}\".format(round(_time, 4)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bb4fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting Results\n",
    "\n",
    "#Loss\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(np.arange(1, 11, 1), train_logs[\"loss\"], color = 'blue')\n",
    "plt.plot(np.arange(1, 11, 1), val_logs[\"loss\"], color = 'yellow')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "#Accuracy\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(np.arange(1, 11, 1), train_logs[\"accuracy\"], color = 'blue')\n",
    "plt.plot(np.arange(1, 11, 1), val_logs[\"accuracy\"], color = 'yellow')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466ecb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
